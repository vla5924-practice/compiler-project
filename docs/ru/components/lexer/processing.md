# Работа анализатора

Программа анализируется построчно. Каждая строка программы разбивается на токены следующих типов:
* ключевые слова; 
* операторы;
* идентификаторы – имена переменных и функций;
* числовые литералы – последовательность символов, состоящая из цифр;
* строковые литералы – последовательность символов, заключенных в двойные кавычки;
* специальные – набор лексем необходимых только для составления синтаксических деревьев.

Под токеном понимается структура данных, содержащая два поля:
* тип токена – пометка необходимая для дальнейших стадий анализа;
* атрибут – значение.

Опишем работу лексического анализатора.
Изначально для каждой поступающей строки производится выделение отступов и формирование соответствующих им токенов с учетом правил языка (каждый отступ должен содержать в себе 4 пробела). Далее создаются два итератора, соответствующие началу и концу анализируемой подстроки. В зависимости от содержащихся в ней символов выполняется одна из процедур для создания токенов:
* Создание токенов для ключевых слов и идентификаторов. Если подстрока состоит только из букв, то выполняется проверка, не является ли она одним из ключевых слов языка, в противном случае подстрока будет считаться идентификатором.
* Создание токенов для числовых литералов. Если подстрока начинается с цифры, то продолжаем сдвигать итератор до тех пор, пока нам не попадётся символ отличный от цифры. Исключение составляет символ «.», если был встречен такой символ, то продолжаем считывать цифры, стоящие после нее. Таким образом, при встрече символа «.» формируются числовые литералы с плавающей точкой, а иначе целочисленные литералы.
* Создание токенов для строковых литералов. Если подстрока начинается с «”», то продолжаем сдвигать итератор до тех пор, пока нам не попадётся следующая «”». Символы, заключенные между кавычками, будем считать строковым литералом.
* Создание токенов для операторов и специальных символов. Если при анализе был встречен один из символов, относящихся к операторам или специальным символам, то будет создан токен соответствующего типа оператора. Анализатор формирует токены операторов максимальной длины, то есть, если были встречены символы «!», «=», «<», «>», то необходимо посмотреть, не следует ли за ними символ «=», в зависимости от этого будут формироваться различные токены.

Стоит отметить, что лексический анализатор не проверяет осмысленность последовательности токенов, то есть строка `a 1.0 if b +` будет являтся абсолютно корректной. 

[_Назад_](README.md)
